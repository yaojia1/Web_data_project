{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Managua\thttps://en.wikipedia.org/wiki/Managua\n",
      "Nicaragua\thttps://en.wikipedia.org/wiki/Nicaragua\n",
      "National Assembly\thttps://en.wikipedia.org/wiki/National_Assembly\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from wikipediaapi import Wikipedia\n",
    "\n",
    "class NLTKStanfordNER:\n",
    "    \"\"\"\n",
    "    Named Entity Recognizer using NLTK and Stanford NER.\n",
    "\n",
    "    @param stanford_ner_path: Path to the Stanford NER tool directory.\n",
    "    @param jar_path: Path to the Stanford NER JAR file.\n",
    "    @param model_path: Path to the Stanford NER model file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stanford_ner_path, jar_path, model_path):\n",
    "        \"\"\"\n",
    "        Initialize the Named Entity Recognizer.\n",
    "\n",
    "        @param stanford_ner_path: Path to the Stanford NER tool directory.\n",
    "        @param jar_path: Path to the Stanford NER JAR file.\n",
    "        @param model_path: Path to the Stanford NER model file.\n",
    "        \"\"\"\n",
    "        self.stanford_ner_path = stanford_ner_path\n",
    "        self.jar_path = jar_path\n",
    "        self.model_path = model_path\n",
    "        self.stanford_ner = nltk.tag.StanfordNERTagger(model_filename=model_path, path_to_jar=jar_path)\n",
    "        self.wikipedia = Wikipedia(user_agent='WDPS 13')\n",
    "\n",
    "\n",
    "    # Need to adjust the preprocessing function, for now doesnt work, doesnt return anything\n",
    "    def process_text(self, text, current_entity=\"\", stemmed=True):\n",
    "        \"\"\"\n",
    "        Tokenize, remove stop words, and apply stemming to the input text.\n",
    "\n",
    "        @param text: Input text to be processed.\n",
    "        @param current_entity: The current entity being processed.\n",
    "        @param stemmed: Flag indicating whether to apply stemming. Default is True.\n",
    "        @return: List of processed words.\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Tokenize the text\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Remove stop words and stemming\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \"\"\"\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            if word.lower() not in stop_words and len(word) > 1:\n",
    "                processed_words.append(ps.stem(word) if stemmed else word)\n",
    "\n",
    "        return processed_words\n",
    "        \"\"\"\n",
    "\n",
    "    def entity_extraction(self, text):\n",
    "        \"\"\"\n",
    "        Extract named entities from the input text.\n",
    "\n",
    "        @param text: Input text containing named entities.\n",
    "        @return: List of unique entities with information like name, type, and Wikipedia page URL.\n",
    "        \"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        tagged_entities = self.stanford_ner.tag(words)\n",
    "\n",
    "        entities_dict = {}\n",
    "        current_entity = \"\"\n",
    "        for word, tag in tagged_entities:\n",
    "            if tag != 'O':\n",
    "                current_entity += word + \" \"\n",
    "            elif current_entity:\n",
    "                current_entity = current_entity.strip()\n",
    "                wikipedia_page = self.get_wikipedia_page(current_entity)\n",
    "                if wikipedia_page.exists():\n",
    "                    url = wikipedia_page.fullurl\n",
    "                    if url not in entities_dict:\n",
    "                        entities_dict[url] = {\n",
    "                            'name': current_entity,\n",
    "                            'type': tag,\n",
    "                            'wikipedia_page': url\n",
    "                        }\n",
    "                current_entity = \"\"\n",
    "\n",
    "        # Filter out entities with the same Wikipedia URL\n",
    "        unique_entities = list(entities_dict.values())\n",
    "\n",
    "        return unique_entities\n",
    "\n",
    "    def get_wikipedia_page(self, entity):\n",
    "        \"\"\"\n",
    "        Fetch the Wikipedia page for a given entity.\n",
    "\n",
    "        @param entity: The entity for which to fetch the Wikipedia page.\n",
    "        @return: Wikipedia page object or None if an error occurs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.wikipedia.page(entity)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Wikipedia page for {entity}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "stanford_ner_path = '/Users/ranjan/Downloads/stanford-ner-2020-11-17'\n",
    "jar_path = os.path.join(stanford_ner_path, 'stanford-ner.jar')\n",
    "model_path = os.path.join(stanford_ner_path, 'classifiers/english.all.3class.distsim.crf.ser.gz')\n",
    "\n",
    "nltk_stanford_ner = NLTKStanfordNER(stanford_ner_path, jar_path, model_path)\n",
    "\n",
    "# Replace the following with your text\n",
    "sample_text = \"Yes, Managua is the capital city of Nicaragua. It is located in the southwestern part of the country and is home to many important government buildings and institutions, including the President's office and the National Assembly. The city has a population of over one million people and is known for its vibrant cultural scene, historic landmarks, and beautiful natural surroundings.\"\n",
    "\n",
    "entities = nltk_stanford_ner.entity_extraction(sample_text)\n",
    "for entity in entities:\n",
    "    print(f\"{entity['name']}\\t{entity['wikipedia_page']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
